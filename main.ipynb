{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jukit_cell_id": "Alw1Pc1YI9"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "vQ89hJuGBe"
      },
      "outputs": [],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "dry_bean_dataset = fetch_ucirepo(id=602)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "features = dry_bean_dataset.data.features\n",
        "labels = dry_bean_dataset.data.targets\n",
        "\n",
        "# Lable Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "x = label_encoder.fit_transform(labels)\n",
        "\n",
        "# converting the lables to tensor\n",
        "tensor_labels = torch.tensor(x, dtype=torch.float32)\n",
        "\n",
        "# Encoding the dataset to extract the features out of it\n",
        "print(tensor_labels)\n",
        "\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "    features, x, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "V9u91SEEJW"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.x = torch.tensor(features.values, dtype=torch.float32)\n",
        "        self.y = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "# Create instances of your custom datasets\n",
        "train_dataset = CustomImageDataset(features_train, labels_train)\n",
        "test_dataset = CustomImageDataset(features_test, labels_test)\n",
        "\n",
        "# Create custom data loaders for training and test sets\n",
        "batch_size = 32\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "HR6k1Hu1Db"
      },
      "outputs": [],
      "source": [
        "class MultiLayerPerceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiLayerPerceptron, self).__init__()\n",
        "        self.layer = nn.Linear(16, 32)\n",
        "        self.second_layer = nn.Linear(32, 7)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.second_relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, tensor):\n",
        "        output = self.layer(tensor)\n",
        "        output = self.relu(output)\n",
        "        output = self.second_layer(output)\n",
        "        output = self.second_relu(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "model = MultiLayerPerceptron()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "eqoCKdhFpE"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "epochs = 100\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jukit_cell_id": "RJ7BrESJex"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model()\n",
        "    test_loss = criterion(test_outputs, test_dataset.y)\n",
        "    predicted_labels = torch.argmax(test_outputs, dim=1)\n",
        "\n",
        "# set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# initialize variables to store the validation loss and accuracy for this epoch\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "# evaluate the model on the validation data\n",
        "with torch.no_grad():\n",
        "    for X, y in test_data_loader:\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y.long())\n",
        "\n",
        "        test_loss += loss.item() * X.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += y.size(0)\n",
        "        test_correct += (predicted == y).sum().item()\n",
        "\n",
        "# calculate the test loss and accuracy for this epoch\n",
        "test_loss /= len(test_data_loader.dataset)\n",
        "test_acc = test_correct / test_total\n",
        "\n",
        "# print the test loss and accuracy for this epoch\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
